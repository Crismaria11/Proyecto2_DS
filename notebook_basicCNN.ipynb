{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proyecto 2. Analisis Exploratorio","metadata":{}},{"cell_type":"markdown","source":"## Deteccion de covid en radiografias de torax","metadata":{}},{"cell_type":"markdown","source":"### Integrantes\n#### Cristina Bautista 161260\n#### Jose Block 18935\n#### Esteban Cabrera 17781\n#### Byron Mota 15246","metadata":{}},{"cell_type":"markdown","source":"Primero correr esta dependecia","metadata":{}},{"cell_type":"code","source":"!pip3 install python-gdcm\nimport gdcm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Resetear y volver a correr","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n!pip install --upgrade numpy\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport pydicom as dicom\nimport cv2\nimport ast\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/input/siim-covid19-detection/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')\ndf2 = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['id_dcm'] = df1['id']\ndf1['id_dcm'] = df1['id'].str.replace('_image', '.dcm')\ndf1['id'] = df1['id'].str.replace('_image', '')\ndf2['id'] = df2['id'].str.replace('_study', '')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.merge(df1, df2, left_on='StudyInstanceUID', right_on='id', how='inner')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se uso de guia para leer los archivos .dcm del repositorio: https://www.kaggle.com/drcapa/siim-fisabio-rsna-covid-19-detection-starter","metadata":{}},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/siim-covid19-detection/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = df.loc[0, 'StudyInstanceUID']\ntemp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_depth2 = os.listdir(path+'train/'+temp)\ntemp_depth2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_train_path = path+'train/'+temp+'/'+temp_depth2[0]\ntemp_train_path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(temp_train_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extraction(i):\n    data_file = dicom.dcmread(complete_path_train)\n    img = data_file.pixel_array\n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extractionPath(i):\n    path_train = path + 'train/' + df.loc[i, 'StudyInstanceUID']\n    last_folder_in_path = os.listdir(path_train)[0]\n    path_train = path_train + '/{}/'.format(last_folder_in_path)\n    img_id = df.loc[i, 'id_dcm']\n    complete_path_train = path_train + img_id\n    return complete_path_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_paths = []\nfor i in range(len(df)):\n     img_paths.append(extractionPath(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(img_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Image_Path'] = img_paths","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.eq('65761e66de9f').any(1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = [x for x in paths if \"test\" not in x and 'csv' not in x]\npath[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_paths = []\nfor i in df['id_dcm']:\n    for j in path:\n        if i == j[-16:-1]:\n            order_paths.append(j)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_paths","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport time\ndef extract_resized_and_origin_img_info(path_list):\n    img_list = []\n    origin_img_heights = []\n    origin_img_widths = []\n    i = 0\n    for path in path_list:\n        data_file = dicom.read_file(path)\n        img = data_file.pixel_array\n\n            \n        origin_img_heights.append(img.shape[0])\n        origin_img_widths.append(img.shape[1])\n\n        \n        # scailing to 0~255\n        img = (img - np.min(img)) / np.max(img)\n        img = (img * 255).astype(np.uint8)\n        \n        # resizing to 4000+ to 255 default\n        img = cv2.resize(img, (255,255))\n        img_list.append(img)\n        img_array = np.array(img_list)\n        i += 1\n        if i % 100 == 0:\n            print('{} / {}'.format(len(img_array),len(path_list)))\n            time.sleep(2)\n    return img_array, origin_img_heights, origin_img_widths","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs_new, origin_img_heights2, origin_img_widths2 = extract_resized_and_origin_img_info(path[:100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(test_imgs_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs_new = np.array(test_imgs_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs_new.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs_new_4dim = test_imgs_new[0:1,:,:,np.newaxis]\ntest_imgs_new_4dim.shape","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_scale_list=[]\ny_scale_list=[]\nif len(origin_img_heights2) == len(origin_img_widths2):\n    for i in range(len(origin_img_heights2)):\n        x_scale = 255 / origin_img_widths2[i]\n        x_scale_list.append(x_scale)\n        print(i)\n        y_scale = 255 / origin_img_heights2[i]\n        y_scale_list.append(y_scale)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clasificadores = list(df.columns[6:10])\nclasificadores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ./genData\n!mkdir ./genData/NegPeu\n!mkdir ./genData/Typical\n!mkdir ./genData/Indeterminate\n!mkdir ./genData/Atypical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_NegPeu = list(df[df[clasificadores[0]]==1].index)\nfor idx in imgs_NegPeu:\n    plt.imsave('./genData/NegPeu/{}.jpg'.format(df.loc[idx,'id_x']), test_imgs_new[idx], cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_Typical = list(df[df[clasificadores[1]]==1].index)\nfor idx in imgs_Typical:\n    plt.imsave('./genData/Typical/{}.jpg'.format(df.loc[idx,'id_x']), test_imgs_new[idx], cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_Indeterminate = list(df[df[clasificadores[2]]==1].index)\nfor idx in imgs_Indeterminate:\n    plt.imsave('./genData/Indeterminate/{}.jpg'.format(df.loc[idx,'id_x']), test_imgs_new[idx], cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_Atypical = list(df[df[clasificadores[3]]==1].index)\nfor idx in imgs_Atypical:\n    plt.imsave('./genData/Atypical/{}.jpg'.format(df.loc[idx,'id_x']), train_imgs[idx], cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idatagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range=3,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    zoom_range=0.05,\n    horizontal_flip=False,\n    fill_mode='reflect',\n    validation_split=0.2\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = idatagen.flow_from_directory(\n    './genData',\n    batch_size=64,\n    target_size=(256, 256),\n    class_mode='categorical',\n    color_mode='grayscale',\n    subset = 'training'\n)\n\nvalid_gen = idatagen.flow_from_directory(\n    './genData',\n    batch_size = 64,\n    target_size = (256, 256),\n    class_mode = 'categorical',\n    color_mode='grayscale',\n    subset = 'validation'\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clasificador Básico","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(64, (3,3), activation='relu', input_shape=(256, 256,1)),\n    MaxPooling2D(2,2),\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    Flatten(),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dense(4, activation='softmax')\n])\nmodel.summary() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    filepath = './checkpoint1.ckpt',\n    save_weights_only = True,\n    save_best_only = True,\n    monitor = 'val_loss',\n    verbose=1\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    train_gen,\n    validation_data = (valid_gen),\n    epochs = 20,\n    callbacks=[checkpoint]\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./checkpoint1.ckpt')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(valid_gen)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./baseCnn.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(test_imgs_new_4dim)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = input('Ingrese el directorio de una imagen')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a_4dim = a[:,:,:,np.newaxis]\na_4dim.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(a_4dim)","metadata":{},"execution_count":null,"outputs":[]}]}